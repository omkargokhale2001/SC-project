{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11425862,"sourceType":"datasetVersion","datasetId":7148190}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:50.343361Z","iopub.execute_input":"2025-04-15T20:01:50.343690Z","iopub.status.idle":"2025-04-15T20:01:50.348627Z","shell.execute_reply.started":"2025-04-15T20:01:50.343666Z","shell.execute_reply":"2025-04-15T20:01:50.347305Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/twibot-sc-text/robert_embs.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:50.350560Z","iopub.execute_input":"2025-04-15T20:01:50.350885Z","iopub.status.idle":"2025-04-15T20:01:52.512249Z","shell.execute_reply.started":"2025-04-15T20:01:50.350863Z","shell.execute_reply":"2025-04-15T20:01:52.511136Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df['label_x'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:52.513300Z","iopub.execute_input":"2025-04-15T20:01:52.513560Z","iopub.status.idle":"2025-04-15T20:01:52.520582Z","shell.execute_reply.started":"2025-04-15T20:01:52.513541Z","shell.execute_reply":"2025-04-15T20:01:52.519690Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"label_x\n0    5000\n1    5000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"y = df[\"label_x\"]\nX = df.drop([\"id\", \"label_x\", \"text\", \"label_y\"], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:52.522755Z","iopub.execute_input":"2025-04-15T20:01:52.522989Z","iopub.status.idle":"2025-04-15T20:01:52.563690Z","shell.execute_reply.started":"2025-04-15T20:01:52.522964Z","shell.execute_reply":"2025-04-15T20:01:52.562696Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:52.564617Z","iopub.execute_input":"2025-04-15T20:01:52.565028Z","iopub.status.idle":"2025-04-15T20:01:52.589109Z","shell.execute_reply.started":"2025-04-15T20:01:52.564928Z","shell.execute_reply":"2025-04-15T20:01:52.588185Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"             0         1         2         3         4         5         6  \\\n0    -0.063839  0.045821  0.037418 -0.005265 -0.023820 -0.147985  0.041368   \n1    -0.088703 -0.028094  0.033069  0.000010  0.057710 -0.186109 -0.033170   \n2    -0.089905  0.044870  0.045571  0.020343  0.002174 -0.019310 -0.025727   \n3    -0.026522  0.056313  0.005001 -0.035982  0.021892 -0.073461  0.030592   \n4    -0.036116 -0.003888  0.075635 -0.069689  0.139981 -0.103635  0.013286   \n...        ...       ...       ...       ...       ...       ...       ...   \n9995 -0.035099 -0.074625  0.044380 -0.082415 -0.101543 -0.162850  0.018927   \n9996 -0.065824  0.008357  0.016951 -0.005660 -0.021456 -0.150749 -0.018298   \n9997 -0.024026 -0.008164  0.034027 -0.054016 -0.032265 -0.158608  0.015137   \n9998 -0.038052  0.018908 -0.011875  0.096292 -0.036807 -0.115779  0.010271   \n9999 -0.031262 -0.002747  0.071747 -0.004553  0.034538 -0.018567  0.036331   \n\n             7         8         9  ...       765       766       767  \\\n0     0.268481  0.093845 -0.051491  ...  0.017669 -0.030149  0.013853   \n1     0.113711  0.075059 -0.039108  ... -0.151111  0.006792 -0.010179   \n2     0.166047  0.141430 -0.014809  ... -0.121637 -0.019821  0.014884   \n3     0.234562  0.041704 -0.105489  ... -0.076468 -0.004578  0.033274   \n4     0.283860  0.048024 -0.130018  ... -0.043109 -0.041146  0.052608   \n...        ...       ...       ...  ...       ...       ...       ...   \n9995  0.126560  0.147278  0.028809  ... -0.111897 -0.046763 -0.001257   \n9996  0.154561  0.045559 -0.057149  ... -0.065827 -0.014392  0.067680   \n9997  0.248405  0.035772 -0.038946  ... -0.084502 -0.020296  0.050531   \n9998  0.094737 -0.010851 -0.086748  ... -0.187321  0.028381  0.009603   \n9999  0.175089 -0.036960 -0.047309  ... -0.021852  0.062583  0.053969   \n\n      description_len  protected  followers_count  following_count  \\\n0                 158          0              456             1387   \n1                 153          0             4704             3576   \n2                  67          0            24628              539   \n3                  94          0              326              182   \n4                  42          0              437              318   \n...               ...        ...              ...              ...   \n9995               54          0              403              740   \n9996               45          0              654              528   \n9997                3          0               18              200   \n9998                3          0              378              672   \n9999               83          0            72853            44912   \n\n      tweet_count  listed_count  verified  \n0            1962            19         0  \n1            7153            38         0  \n2            4987           239         1  \n3             168             2         0  \n4            3356             3         0  \n...           ...           ...       ...  \n9995        15576            12         0  \n9996          626            13         0  \n9997          665             1         0  \n9998         2276            21         0  \n9999         6835          1464         0  \n\n[10000 rows x 775 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>description_len</th>\n      <th>protected</th>\n      <th>followers_count</th>\n      <th>following_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.063839</td>\n      <td>0.045821</td>\n      <td>0.037418</td>\n      <td>-0.005265</td>\n      <td>-0.023820</td>\n      <td>-0.147985</td>\n      <td>0.041368</td>\n      <td>0.268481</td>\n      <td>0.093845</td>\n      <td>-0.051491</td>\n      <td>...</td>\n      <td>0.017669</td>\n      <td>-0.030149</td>\n      <td>0.013853</td>\n      <td>158</td>\n      <td>0</td>\n      <td>456</td>\n      <td>1387</td>\n      <td>1962</td>\n      <td>19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.088703</td>\n      <td>-0.028094</td>\n      <td>0.033069</td>\n      <td>0.000010</td>\n      <td>0.057710</td>\n      <td>-0.186109</td>\n      <td>-0.033170</td>\n      <td>0.113711</td>\n      <td>0.075059</td>\n      <td>-0.039108</td>\n      <td>...</td>\n      <td>-0.151111</td>\n      <td>0.006792</td>\n      <td>-0.010179</td>\n      <td>153</td>\n      <td>0</td>\n      <td>4704</td>\n      <td>3576</td>\n      <td>7153</td>\n      <td>38</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.089905</td>\n      <td>0.044870</td>\n      <td>0.045571</td>\n      <td>0.020343</td>\n      <td>0.002174</td>\n      <td>-0.019310</td>\n      <td>-0.025727</td>\n      <td>0.166047</td>\n      <td>0.141430</td>\n      <td>-0.014809</td>\n      <td>...</td>\n      <td>-0.121637</td>\n      <td>-0.019821</td>\n      <td>0.014884</td>\n      <td>67</td>\n      <td>0</td>\n      <td>24628</td>\n      <td>539</td>\n      <td>4987</td>\n      <td>239</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.026522</td>\n      <td>0.056313</td>\n      <td>0.005001</td>\n      <td>-0.035982</td>\n      <td>0.021892</td>\n      <td>-0.073461</td>\n      <td>0.030592</td>\n      <td>0.234562</td>\n      <td>0.041704</td>\n      <td>-0.105489</td>\n      <td>...</td>\n      <td>-0.076468</td>\n      <td>-0.004578</td>\n      <td>0.033274</td>\n      <td>94</td>\n      <td>0</td>\n      <td>326</td>\n      <td>182</td>\n      <td>168</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.036116</td>\n      <td>-0.003888</td>\n      <td>0.075635</td>\n      <td>-0.069689</td>\n      <td>0.139981</td>\n      <td>-0.103635</td>\n      <td>0.013286</td>\n      <td>0.283860</td>\n      <td>0.048024</td>\n      <td>-0.130018</td>\n      <td>...</td>\n      <td>-0.043109</td>\n      <td>-0.041146</td>\n      <td>0.052608</td>\n      <td>42</td>\n      <td>0</td>\n      <td>437</td>\n      <td>318</td>\n      <td>3356</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>-0.035099</td>\n      <td>-0.074625</td>\n      <td>0.044380</td>\n      <td>-0.082415</td>\n      <td>-0.101543</td>\n      <td>-0.162850</td>\n      <td>0.018927</td>\n      <td>0.126560</td>\n      <td>0.147278</td>\n      <td>0.028809</td>\n      <td>...</td>\n      <td>-0.111897</td>\n      <td>-0.046763</td>\n      <td>-0.001257</td>\n      <td>54</td>\n      <td>0</td>\n      <td>403</td>\n      <td>740</td>\n      <td>15576</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>-0.065824</td>\n      <td>0.008357</td>\n      <td>0.016951</td>\n      <td>-0.005660</td>\n      <td>-0.021456</td>\n      <td>-0.150749</td>\n      <td>-0.018298</td>\n      <td>0.154561</td>\n      <td>0.045559</td>\n      <td>-0.057149</td>\n      <td>...</td>\n      <td>-0.065827</td>\n      <td>-0.014392</td>\n      <td>0.067680</td>\n      <td>45</td>\n      <td>0</td>\n      <td>654</td>\n      <td>528</td>\n      <td>626</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>-0.024026</td>\n      <td>-0.008164</td>\n      <td>0.034027</td>\n      <td>-0.054016</td>\n      <td>-0.032265</td>\n      <td>-0.158608</td>\n      <td>0.015137</td>\n      <td>0.248405</td>\n      <td>0.035772</td>\n      <td>-0.038946</td>\n      <td>...</td>\n      <td>-0.084502</td>\n      <td>-0.020296</td>\n      <td>0.050531</td>\n      <td>3</td>\n      <td>0</td>\n      <td>18</td>\n      <td>200</td>\n      <td>665</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>-0.038052</td>\n      <td>0.018908</td>\n      <td>-0.011875</td>\n      <td>0.096292</td>\n      <td>-0.036807</td>\n      <td>-0.115779</td>\n      <td>0.010271</td>\n      <td>0.094737</td>\n      <td>-0.010851</td>\n      <td>-0.086748</td>\n      <td>...</td>\n      <td>-0.187321</td>\n      <td>0.028381</td>\n      <td>0.009603</td>\n      <td>3</td>\n      <td>0</td>\n      <td>378</td>\n      <td>672</td>\n      <td>2276</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>-0.031262</td>\n      <td>-0.002747</td>\n      <td>0.071747</td>\n      <td>-0.004553</td>\n      <td>0.034538</td>\n      <td>-0.018567</td>\n      <td>0.036331</td>\n      <td>0.175089</td>\n      <td>-0.036960</td>\n      <td>-0.047309</td>\n      <td>...</td>\n      <td>-0.021852</td>\n      <td>0.062583</td>\n      <td>0.053969</td>\n      <td>83</td>\n      <td>0</td>\n      <td>72853</td>\n      <td>44912</td>\n      <td>6835</td>\n      <td>1464</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 775 columns</p>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the XGBoost model with default parameters\nmodel = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # Optional: suppress warnings\nmodel.fit(X_train, y_train)\n\n# (Optional) Evaluate the model\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:01:52.590109Z","iopub.execute_input":"2025-04-15T20:01:52.590383Z","iopub.status.idle":"2025-04-15T20:02:10.287315Z","shell.execute_reply.started":"2025-04-15T20:01:52.590364Z","shell.execute_reply":"2025-04-15T20:02:10.285928Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7400\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:10.287913Z","iopub.execute_input":"2025-04-15T20:02:10.288145Z","iopub.status.idle":"2025-04-15T20:02:10.293055Z","shell.execute_reply.started":"2025-04-15T20:02:10.288128Z","shell.execute_reply":"2025-04-15T20:02:10.292039Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:10.293619Z","iopub.execute_input":"2025-04-15T20:02:10.293982Z","iopub.status.idle":"2025-04-15T20:02:10.330044Z","shell.execute_reply.started":"2025-04-15T20:02:10.293949Z","shell.execute_reply":"2025-04-15T20:02:10.328852Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.75      0.73      0.74      1012\n           1       0.73      0.75      0.74       988\n\n    accuracy                           0.74      2000\n   macro avg       0.74      0.74      0.74      2000\nweighted avg       0.74      0.74      0.74      2000\n\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}